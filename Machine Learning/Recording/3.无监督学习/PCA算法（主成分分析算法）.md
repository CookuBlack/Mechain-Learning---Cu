# **PCA算法（主成分分析算法）**

PCA算法是一种无监督算法，常用于数据的可视化。

介绍：PCA算法可以让您获取具有大量特征（50，1000甚至更多）数据，并将特征数据减少到两个特征，也许是三个特征，以便您可以对其进行绘图和可视化。

PCA算法的语言描述：如果有一个二维数据，要将其降为一维，（首先要对数据进行缩放）就选择一个点，画一条合适的直线，使数据在该直线上分布的不那么密集，因为这样可以更大程度保留原有数据信息。

如有以下数据，我们如何将其映射到一维图像上呢？

![image-20231112145941962](C:\Users\CooKu\AppData\Roaming\Typora\typora-user-images\image-20231112145941962.png)

我们通过以下两种方法进行映射：

![image-20231112152037691](C:\Users\CooKu\AppData\Roaming\Typora\typora-user-images\image-20231112152037691.png)

通过观察图像可以知到，方法（1）映射到一维时，得到的点与点之间的距离非常相近，设置有两个点尽心了重合，这很难表示出原来二维数据的特征，而方法（2）映射到一维时，得到的点与点之间的距离分散的均匀，并没有两个点尽心了重合，因此我们需要映射的一维直线就是（2）。

然后确定映射后的具体位置，如点a(2,3)，映射直线的单位向量为：[0.71,0.71] (单位向量时分别计算在原来x轴y轴上的单位向量在z轴上的投影长度)，得到a点映射后的坐标为：2\*0.71+3\*0.71 = 3.55 即降维后的坐标为：3.55

![image-20231112152946282](C:\Users\CooKu\AppData\Roaming\Typora\typora-user-images\image-20231112152946282.png)

## 注意PCA算法与线性回归不一样

最直观的理解：

![image-20231112153417396](C:\Users\CooKu\AppData\Roaming\Typora\typora-user-images\image-20231112153417396.png)

重建：通过降维后的数据来反推原来的坐标（但只能得到合理的近似值），只需将映射后的坐标乘上映射直线的单位向量即可。

如：3.55*（0.71，0.71） = （2.52，2.52）

## PCA代码实现

```python
X = np.array([[1,1],[2,1],[3,2],[-1,-1],[-2,-1],[-3,-2]])
pac_1 = PCA(n_components = 1)  #将二维拟合成一维数据
pca_1.fit(X)  #进行拟合，且具有自动归一化

pca_1.explaiined_variance_ratio_  #拟合后直线对数据的可解释性，如：0.9928则表示捕获原始数据集中99.2%的可变性或信息
X_trans_1 = pac_1.transform(X)  # 进行转换，将二维数据（如：x1,x2)转换到一维数据对应的坐标（如：z1)

X_reduce_1 = pca_1.inverse_transform(X_trans_1)  #输出转换后的数组
```

## 其他用途

1. 在网络上传输多个特征的数据可以使用PCA算法来减少特征，对数据进行压缩，可以减少网络传输成本
2. 加速监督学习模型的训练（如支持向量机）
3. 不常用于深度学习算法，通常是直接将高维数据进行输入，因为PCA也有一些计算成本
4. 最常见的是PCA算法用于数据可视化。